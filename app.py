import streamlit as st
import openai
import os
from dotenv import load_dotenv
from datetime import datetime
import pandas as pd
from PIL import Image
import pytesseract
import fitz  # for PDF
import io
import cv2
import numpy as np
from utils.translator import explain_report
import logging
from typing import Optional, Tuple
import base64

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Load environment variables
load_dotenv()

# Initialize OpenAI
openai.api_key = os.getenv("OPENAI_API_KEY")

# Page configuration
st.set_page_config(
    page_title="Radi.AI Care",
    page_icon="ü©∫",
    layout="centered",
    initial_sidebar_state="collapsed"
)

# Custom CSS for better mobile experience
st.markdown("""
<style>
    .main-header {
        text-align: center;
        padding: 1rem 0;
    }
    
    .language-selector {
        display: flex;
        justify-content: center;
        gap: 10px;
        margin-bottom: 2rem;
    }
    
    .upload-area {
        border: 2px dashed #cccccc;
        border-radius: 10px;
        padding: 2rem;
        text-align: center;
        margin: 1rem 0;
    }
    
    .result-container {
        background-color: #f0f8ff;
        border-radius: 10px;
        padding: 1.5rem;
        margin: 1rem 0;
        border-left: 4px solid #1f77b4;
    }
    
    .warning-box {
        background-color: #fff3cd;
        border: 1px solid #ffecb5;
        border-radius: 5px;
        padding: 1rem;
        margin: 1rem 0;
        color: #856404;
    }
    
    .error-box {
        background-color: #f8d7da;
        border: 1px solid #f5c6cb;
        border-radius: 5px;
        padding: 1rem;
        margin: 1rem 0;
        color: #721c24;
    }
    
    @media (max-width: 768px) {
        .main-header h1 {
            font-size: 1.5rem;
        }
        .language-selector {
            flex-direction: column;
            align-items: center;
        }
    }
</style>
""", unsafe_allow_html=True)

# Language configurations
LANGUAGES = {
    "ÁπÅÈ´î‰∏≠Êñá": {
        "title": "ü©∫ Radi.AI Care - Â†±ÂëäÁøªË≠ØÂä©Êâã",
        "upload_label": "‰∏äÂÇ≥Ê™îÊ°àÊàñÂúñÁâá",
        "upload_help": "Ë´ã‰∏äÂÇ≥ÂúñÁâáÊàñÂ†±ÂëäÔºàÊîØÊè¥ .jpg, .png, .pdf, .txtÔºâ",
        "manual_input": "ÊàñÁõ¥Êé•Ë≤º‰∏äËã±ÊñáÂ†±ÂëäÔºö",
        "camera_button": "üì∏ ÊãçÁÖß‰∏äÂÇ≥",
        "generate_button": "üîç ÁîüÊàêËß£Ë™™",
        "processing": "AI Ê≠£Âú®ÁîüÊàê...",
        "back_button": "‚¨ÖÔ∏è ËøîÂõû‰∏ªÈ†Å",
        "camera_mode": "üì∏ ÊãçÁÖß‰∏äÂÇ≥Ê®°Âºè",
        "camera_help": "Ë´ã‰ΩøÁî®ÊâãÊ©üÊàñË®≠ÂÇôÊãçÁÖß",
        "processed_image": "ËôïÁêÜÂæåÂúñÁâá",
        "uploaded_image": "‰Ω†‰∏äÂÇ≥ÁöÑÂúñÁâá",
        "warning": "‚ö†Ô∏è Ê≠§Â∑•ÂÖ∑ÂÉÖ‰æõÂèÉËÄÉÔºåË´ãÂãôÂøÖË´ÆË©¢Â∞àÊ•≠ÈÜ´Â∏´",
        "error_no_content": "‚ùå Ë´ã‰∏äÂÇ≥Ê™îÊ°àÊàñËº∏ÂÖ•Â†±ÂëäÂÖßÂÆπ",
        "error_processing": "‚ùå ËôïÁêÜÈÅéÁ®ã‰∏≠ÁôºÁîüÈåØË™§Ôºö",
        "error_ocr": "‚ùå ÂúñÁâáÊñáÂ≠óË≠òÂà•Â§±ÊïóÔºåË´ãÂòóË©¶Êõ¥Ê∏ÖÊô∞ÁöÑÂúñÁâá"
    },
    "ÁÆÄ‰Ωì‰∏≠Êñá": {
        "title": "ü©∫ Radi.AI Care - Êä•ÂëäÁøªËØëÂä©Êâã",
        "upload_label": "‰∏ä‰º†Êñá‰ª∂ÊàñÂõæÁâá",
        "upload_help": "ËØ∑‰∏ä‰º†ÂõæÁâáÊàñÊä•ÂëäÔºàÊîØÊåÅ .jpg, .png, .pdf, .txtÔºâ",
        "manual_input": "ÊàñËÄÖÁõ¥Êé•Á≤òË¥¥Ëã±ÊñáÊä•ÂëäÔºö",
        "camera_button": "üì∏ ÊãçÁÖß‰∏ä‰º†",
        "generate_button": "üîç ÁîüÊàêËß£ËØ¥",
        "processing": "AI Ê≠£Âú®ÁîüÊàê...",
        "back_button": "‚¨ÖÔ∏è ËøîÂõû‰∏ªÈ°µ",
        "camera_mode": "üì∏ ÊãçÁÖß‰∏ä‰º†Ê®°Âºè",
        "camera_help": "ËØ∑‰ΩøÁî®ÊâãÊú∫ÊàñËÆæÂ§áÊãçÁÖß",
        "processed_image": "Â§ÑÁêÜÂêéÂõæÁâá",
        "uploaded_image": "‰Ω†‰∏ä‰º†ÁöÑÂõæÁâá",
        "warning": "‚ö†Ô∏è Ê≠§Â∑•ÂÖ∑‰ªÖ‰æõÂèÇËÄÉÔºåËØ∑Âä°ÂøÖÂí®ËØ¢‰∏ì‰∏öÂåªÂ∏à",
        "error_no_content": "‚ùå ËØ∑‰∏ä‰º†Êñá‰ª∂ÊàñËæìÂÖ•Êä•ÂëäÂÜÖÂÆπ",
        "error_processing": "‚ùå Â§ÑÁêÜËøáÁ®ã‰∏≠ÂèëÁîüÈîôËØØÔºö",
        "error_ocr": "‚ùå ÂõæÁâáÊñáÂ≠óËØÜÂà´Â§±Ë¥•ÔºåËØ∑Â∞ùËØïÊõ¥Ê∏ÖÊô∞ÁöÑÂõæÁâá"
    },
    "English": {
        "title": "ü©∫ Radi.AI Care - Report Translation Assistant",
        "upload_label": "Upload File or Image",
        "upload_help": "Please upload an image or report (supports .jpg, .png, .pdf, .txt)",
        "manual_input": "Or paste your English radiology report directly:",
        "camera_button": "üì∏ Take Photo",
        "generate_button": "üîç Generate Explanation",
        "processing": "AI is generating...",
        "back_button": "‚¨ÖÔ∏è Back to Main",
        "camera_mode": "üì∏ Camera Upload Mode",
        "camera_help": "Please use your phone or device to take a photo",
        "processed_image": "Processed Image",
        "uploaded_image": "Your Uploaded Image",
        "warning": "‚ö†Ô∏è This tool is for reference only. Please consult a professional physician",
        "error_no_content": "‚ùå Please upload a file or enter report content",
        "error_processing": "‚ùå Error occurred during processing: ",
        "error_ocr": "‚ùå Failed to recognize text from image. Please try a clearer image"
    }
}

def initialize_session_state():
    """Initialize session state variables"""
    if "language" not in st.session_state:
        st.session_state.language = "ÁÆÄ‰Ωì‰∏≠Êñá"
    if "mode" not in st.session_state:
        st.session_state.mode = "main"
    if "processed_report" not in st.session_state:
        st.session_state.processed_report = ""
    if "processing_history" not in st.session_state:
        st.session_state.processing_history = []

def detect_device() -> bool:
    """Detect if user is on mobile device"""
    import streamlit.components.v1 as components
    
    components.html("""
        <script>
            const isMobile = /Mobi|Android/i.test(navigator.userAgent);
            window.parent.postMessage(isMobile ? "mobile" : "desktop", "*");
        </script>
    """, height=0)
    
    return "mobile" in st.session_state.get("device", "")

def preprocess_image(image: Image.Image) -> Image.Image:
    """Preprocess image for better OCR results"""
    try:
        # Convert PIL Image to numpy array
        img_np = np.array(image)
        
        # Convert to grayscale
        if len(img_np.shape) == 3:
            gray = cv2.cvtColor(img_np, cv2.COLOR_RGB2GRAY)
        else:
            gray = img_np
            
        # Apply adaptive thresholding for better text extraction
        binary = cv2.adaptiveThreshold(
            gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2
        )
        
        # Noise removal
        kernel = np.ones((1, 1), np.uint8)
        binary = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)
        binary = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel)
        
        return Image.fromarray(binary)
    except Exception as e:
        logger.error(f"Image preprocessing error: {e}")
        return image

def extract_text_from_image(image: Image.Image) -> str:
    """Extract text from image using OCR"""
    try:
        # Preprocess image
        processed_image = preprocess_image(image)
        
        # Try multiple OCR configurations
        configs = [
            '--psm 6',  # Single uniform block
            '--psm 4',  # Single column of text
            '--psm 3',  # Default
        ]
        
        for config in configs:
            try:
                text = pytesseract.image_to_string(processed_image, config=config)
                if text.strip():
                    return text.strip()
            except:
                continue
                
        return ""
    except Exception as e:
        logger.error(f"OCR error: {e}")
        return ""

def process_uploaded_file(uploaded_file) -> Tuple[str, Optional[str]]:
    """Process uploaded file and extract text"""
    try:
        filename = uploaded_file.name.lower()
        
        if filename.endswith(".txt"):
            return uploaded_file.read().decode("utf-8"), None
            
        elif filename.endswith(".pdf"):
            with fitz.open(stream=uploaded_file.read(), filetype="pdf") as doc:
                text = "\n".join([page.get_text() for page in doc])
                return text, None
                
        elif filename.endswith((".jpg", ".jpeg", ".png")):
            image = Image.open(io.BytesIO(uploaded_file.read()))
            text = extract_text_from_image(image)
            return text, image
            
        else:
            return "", None
            
    except Exception as e:
        logger.error(f"File processing error: {e}")
        return "", None

def display_language_selector():
    """Display language selection buttons"""
    st.markdown("### üåê Ë´ãÈÅ∏ÊìáË™ûË®Ä / Choose Language")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        if st.button("ÁπÅÈ´î‰∏≠Êñá", key="lang_tc"):
            st.session_state.language = "ÁπÅÈ´î‰∏≠Êñá"
            st.rerun()
    
    with col2:
        if st.button("ÁÆÄ‰Ωì‰∏≠Êñá", key="lang_sc"):
            st.session_state.language = "ÁÆÄ‰Ωì‰∏≠Êñá"
            st.rerun()
    
    with col3:
        if st.button("English", key="lang_en"):
            st.session_state.language = "English"
            st.rerun()

def display_header():
    """Display app header"""
    is_mobile = detect_device()
    logo_width = 100 if is_mobile else 160
    
    # Display logo if exists
    if os.path.exists("assets/logo.png"):
        st.image("assets/logo.png", width=logo_width)
    
    lang_config = LANGUAGES[st.session_state.language]
    st.markdown(f'<div class="main-header"><h1>{lang_config["title"]}</h1></div>', 
                unsafe_allow_html=True)

def display_disclaimer():
    """Display medical disclaimer"""
    lang_config = LANGUAGES[st.session_state.language]
    st.markdown(f'<div class="warning-box">{lang_config["warning"]}</div>', 
                unsafe_allow_html=True)

def display_main_mode():
    """Display main upload mode"""
    lang_config = LANGUAGES[st.session_state.language]
    report = ""
    uploaded_image = None
    
    # File upload section
    st.markdown(f'<div class="upload-area">', unsafe_allow_html=True)
    st.subheader(f"üì§ {lang_config['upload_label']}")
    
    uploaded_file = st.file_uploader(
        lang_config["upload_help"],
        type=["jpg", "jpeg", "png", "pdf", "txt"],
        key="combined_upload"
    )
    
    if uploaded_file:
        with st.spinner(lang_config["processing"]):
            report, uploaded_image = process_uploaded_file(uploaded_file)
            
            if uploaded_image:
                st.image(uploaded_image, caption=lang_config["uploaded_image"], 
                        use_container_width=True)
            
            if not report.strip():
                st.error(lang_config["error_ocr"])
    
    st.markdown('</div>', unsafe_allow_html=True)
    
    # Camera upload button
    if st.button(f"{lang_config['camera_button']}", key="camera_btn"):
        st.session_state.mode = "camera"
        st.rerun()
    
    # Manual input section
    st.markdown("---")
    st.markdown(lang_config["manual_input"])
    manual_input = st.text_area("", value=report, height=200, key="manual_input")
    
    if manual_input:
        report = manual_input
    
    # Generate explanation button
    if st.button(f"{lang_config['generate_button']}", key="generate_btn"):
        if not report.strip():
            st.error(lang_config["error_no_content"])
        else:
            generate_explanation(report)

def display_camera_mode():
    """Display camera upload mode"""
    lang_config = LANGUAGES[st.session_state.language]
    
    st.subheader(lang_config["camera_mode"])
    
    camera_image = st.camera_input(lang_config["camera_help"])
    
    if camera_image:
        with st.spinner(lang_config["processing"]):
            img = Image.open(io.BytesIO(camera_image.getvalue()))
            processed_img = preprocess_image(img)
            
            st.image(processed_img, caption=lang_config["processed_image"], 
                    use_container_width=True)
            
            report = extract_text_from_image(img)
            
            if report.strip():
                st.session_state.processed_report = report
                st.text_area("Extracted Text:", value=report, height=150)
                
                if st.button(f"{lang_config['generate_button']}", key="camera_generate"):
                    generate_explanation(report)
            else:
                st.error(lang_config["error_ocr"])
    
    if st.button(f"{lang_config['back_button']}", key="back_btn"):
        st.session_state.mode = "main"
        st.rerun()

def generate_explanation(report: str):
    """Generate AI explanation for the report"""
    lang_config = LANGUAGES[st.session_state.language]
    
    try:
        with st.spinner(lang_config["processing"]):
            result = explain_report(report, st.session_state.language)
            
            st.markdown('<div class="result-container">', unsafe_allow_html=True)
            st.markdown(result, unsafe_allow_html=True)
            st.markdown('</div>', unsafe_allow_html=True)
            
            # Log usage
            try:
                from log_to_sheets import log_to_google_sheets
                log_to_google_sheets(st.session_state.language, len(report))
            except Exception as log_error:
                logger.warning(f"Failed to log usage: {log_error}")
                
            # Store in history
            st.session_state.processing_history.append({
                'timestamp': datetime.now(),
                'language': st.session_state.language,
                'report_length': len(report),
                'result': result
            })
            
    except Exception as e:
        logger.error(f"Generation error: {e}")
        st.error(f"{lang_config['error_processing']}{str(e)}")

def main():
    """Main application function"""
    # Initialize session state
    initialize_session_state()
    
    # Display header
    display_header()
    
    # Display language selector
    display_language_selector()
    
    # Display disclaimer
    display_disclaimer()
    
    # Display appropriate mode
    if st.session_state.mode == "main":
        display_main_mode()
    elif st.session_state.mode == "camera":
        display_camera_mode()
    
    # Display usage statistics in sidebar (optional)
    if st.session_state.processing_history:
        with st.sidebar:
            st.markdown("### üìä Usage Statistics")
            df = pd.DataFrame(st.session_state.processing_history)
            st.markdown(f"**Total Reports Processed:** {len(df)}")
            if not df.empty:
                lang_counts = df['language'].value_counts()
                st.markdown("**Language Distribution:**")
                for lang, count in lang_counts.items():
                    st.markdown(f"- {lang}: {count}")

if __name__ == "__main__":
    main()
