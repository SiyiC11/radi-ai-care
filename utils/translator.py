"""
RadiAI.Care ç¿»è­¯å¼•æ“
æä¾›å°ˆæ¥­çš„é†«å­¸å ±å‘Šç¿»è­¯å’Œå…§å®¹é©—è­‰åŠŸèƒ½
"""

import time
import logging
from typing import Dict, Any, List, Optional
from openai import OpenAI
import os
from config.settings import AppConfig
from utils.prompt_template import get_prompt, create_enhanced_disclaimer, get_processing_steps

logger = logging.getLogger(__name__)

class ContentValidator:
    """å…§å®¹é©—è­‰å™¨"""
    
    def __init__(self, config: AppConfig):
        self.config = config
        self.medical_keywords = config.MEDICAL_KEYWORDS
        self.min_length = config.MIN_TEXT_LENGTH
        self.max_length = config.MAX_TEXT_LENGTH
    
    def validate_content(self, text: str) -> Dict[str, Any]:
        """
        é©—è­‰æ–‡æœ¬å…§å®¹æ˜¯å¦ç‚ºæœ‰æ•ˆçš„é†«å­¸å ±å‘Š
        
        Args:
            text: å¾…é©—è­‰çš„æ–‡æœ¬
            
        Returns:
            Dict: é©—è­‰çµæœ
        """
        if not text or not text.strip():
            return {
                "is_valid": False,
                "confidence": 0.0,
                "found_terms": [],
                "issues": ["æ–‡æœ¬ç‚ºç©º"],
                "suggestions": ["è«‹è¼¸å…¥æœ‰æ•ˆçš„æ–‡æœ¬å…§å®¹"],
                "structure_score": 0
            }
        
        text = text.strip()
        issues = []
        suggestions = []
        
        # åŸºæœ¬é•·åº¦æª¢æŸ¥
        if len(text) < self.min_length:
            issues.append(f"æ–‡æœ¬éçŸ­ï¼ˆå°‘æ–¼{self.min_length}å­—ç¬¦ï¼‰")
            suggestions.append("è«‹æä¾›æ›´å®Œæ•´çš„å ±å‘Šå…§å®¹")
        
        if len(text) > self.max_length:
            issues.append(f"æ–‡æœ¬éé•·ï¼ˆè¶…é{self.max_length}å­—ç¬¦ï¼‰")
            suggestions.append("è«‹åˆ†æ®µè™•ç†æˆ–ç²¾ç°¡å…§å®¹")
        
        # é†«å­¸è¡“èªæª¢æ¸¬
        found_terms = self._find_medical_terms(text)
        
        # çµæ§‹åŒ–æŒ‡æ¨™æª¢æ¸¬
        structure_score = self._analyze_structure(text)
        
        # è¨ˆç®—ä¿¡å¿ƒåº¦
        confidence = self._calculate_confidence(found_terms, structure_score, len(text))
        
        # é©—è­‰æ¨™æº–
        is_valid = len(found_terms) >= 2 and len(text) >= self.min_length
        
        if len(found_terms) < 2:
            issues.append("é†«å­¸è¡“èªéå°‘")
            suggestions.append("è«‹ç¢ºèªé€™æ˜¯é†«å­¸å ±å‘Š")
        
        if structure_score == 0:
            issues.append("ç¼ºå°‘å ±å‘Šçµæ§‹")
            suggestions.append("è«‹åŒ…å«å®Œæ•´çš„å ±å‘Šæ®µè½")
        
        return {
            "is_valid": is_valid,
            "confidence": confidence,
            "found_terms": found_terms,
            "issues": issues,
            "suggestions": suggestions,
            "structure_score": structure_score,
            "term_categories": self._categorize_terms(found_terms)
        }
    
    def _find_medical_terms(self, text: str) -> List[str]:
        """æŸ¥æ‰¾é†«å­¸è¡“èª"""
        text_lower = text.lower()
        found_terms = []
        
        for term in self.medical_keywords:
            if term in text_lower:
                found_terms.append(term)
        
        return list(set(found_terms))  # å»é‡
    
    def _analyze_structure(self, text: str) -> int:
        """åˆ†ææ–‡æœ¬çµæ§‹ï¼ˆ0-100åˆ†ï¼‰"""
        text_lower = text.lower()
        
        # æª¢æŸ¥å ±å‘Šçµæ§‹æŒ‡æ¨™
        structure_indicators = [
            'impression:', 'findings:', 'technique:', 'clinical history:',
            'examination:', 'study:', 'conclusion:', 'recommendation:',
            'images show', 'no evidence of', 'consistent with'
        ]
        
        found_indicators = sum(1 for indicator in structure_indicators if indicator in text_lower)
        
        # åŸºæ–¼æ‰¾åˆ°çš„çµæ§‹æŒ‡æ¨™è¨ˆç®—åˆ†æ•¸
        if found_indicators >= 3:
            return 100
        elif found_indicators == 2:
            return 80
        elif found_indicators == 1:
            return 60
        else:
            return 0
    
    def _calculate_confidence(self, found_terms: List[str], structure_score: int, text_length: int) -> float:
        """è¨ˆç®—å…§å®¹ä¿¡å¿ƒåº¦"""
        # è¡“èªå¯†åº¦å¾—åˆ†
        term_score = min(len(found_terms) * 0.1, 0.6)
        
        # çµæ§‹å¾—åˆ†
        structure_normalized = structure_score / 100 * 0.3
        
        # é•·åº¦é©å®œæ€§å¾—åˆ†
        if text_length < self.min_length:
            length_score = 0
        elif text_length > self.max_length:
            length_score = 0.05
        else:
            length_score = 0.1
        
        total_confidence = term_score + structure_normalized + length_score
        return min(total_confidence, 1.0)
    
    def _categorize_terms(self, found_terms: List[str]) -> Dict[str, List[str]]:
        """åˆ†é¡æ‰¾åˆ°çš„é†«å­¸è¡“èª"""
        categories = {
            'examination_types': [],
            'anatomy': [],
            'findings': [],
            'procedures': []
        }
        
        examination_terms = ['scan', 'ct', 'mri', 'xray', 'x-ray', 'ultrasound', 'mammogram']
        anatomy_terms = ['chest', 'abdomen', 'brain', 'spine', 'lung', 'heart', 'liver']
        finding_terms = ['lesion', 'mass', 'nodule', 'opacity', 'normal', 'abnormal']
        
        for term in found_terms:
            if term in examination_terms:
                categories['examination_types'].append(term)
            elif term in anatomy_terms:
                categories['anatomy'].append(term)
            elif term in finding_terms:
                categories['findings'].append(term)
            else:
                categories['procedures'].append(term)
        
        return categories

class Translator:
    """å¢å¼·å‹ç¿»è­¯å™¨"""
    
    def __init__(self):
        self.config = AppConfig()
        self.validator = ContentValidator(self.config)
        self._init_openai_client()
    
    def _init_openai_client(self):
        """åˆå§‹åŒ– OpenAI å®¢æˆ¶ç«¯"""
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            raise ValueError("OpenAI APIå¯†é‘°æœªè¨­ç½®")
        self.client = OpenAI(api_key=api_key)
    
    def validate_content(self, text: str) -> Dict[str, Any]:
        """é©—è­‰å…§å®¹"""
        return self.validator.validate_content(text)
    
    def translate_with_progress(self, report_text: str, language_code: str, 
                              progress_bar, status_text) -> Dict[str, Any]:
        """
        å¸¶é€²åº¦é¡¯ç¤ºçš„ç¿»è­¯åŠŸèƒ½
        
        Args:
            report_text: å ±å‘Šæ–‡æœ¬
            language_code: èªè¨€ä»£ç¢¼
            progress_bar: Streamlit é€²åº¦æ¢
            status_text: Streamlit ç‹€æ…‹æ–‡æœ¬
            
        Returns:
            Dict: ç¿»è­¯çµæœ
        """
        try:
            # ç²å–è™•ç†æ­¥é©Ÿ
            steps = get_processing_steps(language_code)
            
            for i, step_text in enumerate(steps):
                status_text.markdown(f"**ğŸ”„ {step_text}**")
                progress_bar.progress(int((i + 1) / len(steps) * 85))
                time.sleep(0.8)
            
            # åŸ·è¡Œç¿»è­¯
            status_text.markdown("**ğŸ¤– AI æ­£åœ¨ç”Ÿæˆè§£è®€çµæœ...**")
            progress_bar.progress(95)
            
            result_text, disclaimer_html = self._perform_translation(report_text, language_code)
            
            progress_bar.progress(100)
            time.sleep(0.3)
            
            return {
                "success": True,
                "content": result_text,
                "disclaimer": disclaimer_html,
                "error": None
            }
            
        except Exception as e:
            logger.error(f"Translation with progress failed: {e}")
            return {
                "success": False,
                "content": None,
                "disclaimer": None,
                "error": str(e)
            }
    
    def _perform_translation(self, report_text: str, language_code: str) -> tuple:
        """åŸ·è¡Œå¯¦éš›çš„ç¿»è­¯"""
        try:
            system_prompt = get_prompt(language_code)
            
            # æ·»åŠ ä¸Šä¸‹æ–‡å¢å¼·
            enhanced_prompt = f"""
            {system_prompt}
            
            è«‹ç‰¹åˆ¥æ³¨æ„ä»¥ä¸‹è¦é»ï¼š
            1. é†«å­¸è¡“èªçš„æº–ç¢ºç¿»è­¯å’Œæœ¬åœ°åŒ–
            2. ä¿æŒåŸå§‹å ±å‘Šçš„çµæ§‹å’Œé‚è¼¯
            3. æä¾›é€šä¿—æ˜“æ‡‚çš„è§£é‡‹ï¼Œä½†ä¸ç°¡åŒ–é‡è¦è³‡è¨Š
            4. æ¨™æ˜ä»»ä½•ä¸ç¢ºå®šæˆ–éœ€è¦å°ˆæ¥­ç¢ºèªçš„å…§å®¹
            """
            
            response = self.client.chat.completions.create(
                model=self.config.OPENAI_MODEL,
                messages=[
                    {"role": "system", "content": enhanced_prompt},
                    {"role": "user", "content": f"è«‹ç¿»è­¯ä¸¦è§£é‡‹ä»¥ä¸‹æ”¾å°„ç§‘å ±å‘Šï¼š\n\n{report_text}"}
                ],
                temperature=self.config.OPENAI_TEMPERATURE,
                max_tokens=self.config.OPENAI_MAX_TOKENS,
                timeout=self.config.OPENAI_TIMEOUT
            )
            
            result_text = response.choices[0].message.content.strip()
            disclaimer_html = create_enhanced_disclaimer(language_code)
            
            return result_text, disclaimer_html
            
        except Exception as e:
            logger.error(f"Translation error: {e}")
            error_msg = str(e).lower()
            
            if "rate limit" in error_msg:
                raise Exception("APIè«‹æ±‚éæ–¼é »ç¹ï¼Œè«‹ç¨å¾Œé‡è©¦")
            elif "timeout" in error_msg:
                raise Exception("è«‹æ±‚è¶…æ™‚ï¼Œè«‹æª¢æŸ¥ç¶²è·¯é€£ç·šå¾Œé‡è©¦")
            elif "api" in error_msg or "openai" in error_msg:
                raise Exception("AIæœå‹™æš«æ™‚ä¸å¯ç”¨ï¼Œè«‹ç¨å¾Œé‡è©¦")
            else:
                raise Exception(f"ç¿»è­¯å¤±æ•—ï¼š{str(e)}")
    
    def estimate_translation_time(self, text_length: int) -> str:
        """ä¼°ç®—ç¿»è­¯æ™‚é–“"""
        if text_length < 500:
            return "10-20ç§’"
        elif text_length < 1500:
            return "20-40ç§’"
        else:
            return "40-60ç§’"
    
    def get_translation_quality_score(self, original_text: str, translated_text: str) -> int:
        """è©•ä¼°ç¿»è­¯è³ªé‡åˆ†æ•¸ï¼ˆ0-100ï¼‰"""
        score = 100
        
        # åŸºæœ¬é•·åº¦æª¢æŸ¥
        original_words = len(original_text.split())
        translated_chars = len(translated_text)
        
        # ç¿»è­¯é•·åº¦åˆç†æ€§
        if translated_chars < original_words * 1.5:
            score -= 30
        elif translated_chars > original_words * 6:
            score -= 20
        
        # çµæ§‹å®Œæ•´æ€§æª¢æŸ¥
        required_sections = ["ğŸ“‹", "ğŸ”", "ğŸ’¡", "â“"]
        missing_sections = sum(1 for section in required_sections if section not in translated_text)
        score -= missing_sections * 15
        
        return max(0, score)
